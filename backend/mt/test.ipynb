{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b2cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9c322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 08:23:17.711975: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-25 08:23:17.758670: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-25 08:23:17.955348: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-25 08:23:18.218315: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753431798.377684   35707 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753431798.422114   35707 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753431798.777187   35707 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753431798.777444   35707 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753431798.777451   35707 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753431798.777453   35707 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-25 08:23:18.857522: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-25 08:23:26.641932: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "äºˆæ¸¬çµæœã‚’CSVã¨ã—ã¦ä¿å­˜ã—ã¾ã—ãŸ: ./backend/mt/prediction_results.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====== ãƒ‘ã‚¹ã®è¨­å®š ======\n",
    "model_path = './backend/ml'\n",
    "test_path = './backend/mt'\n",
    "model_file = os.path.join(model_path, 'sports_classification_model.h5')\n",
    "label_file = os.path.join(model_path, 'class_indices.json')\n",
    "test_root = './kagglehub_cache/datasets/gpiosenka/sports-classification/versions/9/test'\n",
    "\n",
    "# ====== ãƒ¢ãƒ‡ãƒ«ã¨ãƒ©ãƒ™ãƒ«ã®èª­ã¿è¾¼ã¿ ======\n",
    "model = load_model(model_file)\n",
    "\n",
    "with open(label_file, 'r', encoding='utf-8') as f:\n",
    "    class_indices = json.load(f)\n",
    "class_labels = {int(v): k for k, v in class_indices.items()}\n",
    "\n",
    "# ====== æ¨è«–å‡¦ç† ======\n",
    "results = []\n",
    "image_id = 1\n",
    "\n",
    "for true_class in sorted(os.listdir(test_root)):\n",
    "    class_dir = os.path.join(test_root, true_class)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "\n",
    "    for fname in sorted(os.listdir(class_dir)):\n",
    "        fpath = os.path.join(class_dir, fname)\n",
    "        if not fpath.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            continue\n",
    "\n",
    "        # ç”»åƒèª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†\n",
    "        img = image.load_img(fpath, target_size=(64, 64))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "        # äºˆæ¸¬\n",
    "        preds = model.predict(img_array, verbose=0)[0]\n",
    "        top_indices = preds.argsort()[-3:][::-1]\n",
    "        top_labels = [class_labels[i] for i in top_indices]\n",
    "\n",
    "        # çµæœè¨˜éŒ²\n",
    "        results.append([\n",
    "            image_id,\n",
    "            true_class,\n",
    "            top_labels[0],\n",
    "            top_labels[1],\n",
    "            top_labels[2]\n",
    "        ])\n",
    "        image_id += 1\n",
    "\n",
    "# ====== CSVä¿å­˜ ======\n",
    "df_results = pd.DataFrame(results, columns=[\"ç”»åƒID\", \"æ­£è§£\", \"Top1äºˆæ¸¬\", \"Top2äºˆæ¸¬\", \"Top3äºˆæ¸¬\"])\n",
    "output_csv_path = os.path.join(test_path, \"prediction_results.csv\")\n",
    "df_results.to_csv(output_csv_path, index=False, encoding='utf-8')\n",
    "print(f\"äºˆæ¸¬çµæœã‚’CSVã¨ã—ã¦ä¿å­˜ã—ã¾ã—ãŸã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "394d3e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Top1ç²¾åº¦: 44.80%\n",
      "ğŸ¯ Top3ç²¾åº¦: 67.00%\n",
      "\n",
      "ğŸ“ˆ ã‚¯ãƒ©ã‚¹åˆ¥ Top1ç²¾åº¦ï¼ˆä¸Šä½10ã‚¯ãƒ©ã‚¹ï¼‰:\n",
      "æ­£è§£\n",
      "billiards             1.0\n",
      "weightlifting         1.0\n",
      "giant slalom          1.0\n",
      "horse racing          1.0\n",
      "water cycling         1.0\n",
      "track bicycle         0.8\n",
      "boxing                0.8\n",
      "sailboat racing       0.8\n",
      "polo                  0.8\n",
      "figure skating men    0.8\n",
      "Name: Top1äºˆæ¸¬, dtype: float64\n",
      "\n",
      "ğŸŒ€ ã‚ˆãã‚ã‚‹æ··åŒä¾‹ï¼ˆTop10ï¼‰:\n",
      "                    æ­£è§£             Top1äºˆæ¸¬  ä»¶æ•°\n",
      "190     sidecar racing      nascar racing   3\n",
      "41             bobsled  snowmobile racing   3\n",
      "248  wheelchair racing                bmx   3\n",
      "52        canoe slamon                bmx   3\n",
      "42             bowling         basketball   2\n",
      "95                gaga                bmx   2\n",
      "160       pole dancing             rowing   2\n",
      "211    steer wrestling       horse racing   2\n",
      "107       hang gliding          skydiving   2\n",
      "154       parallel bar        uneven bars   2\n",
      "\n",
      "ğŸ” äºˆæ¸¬ãƒŸã‚¹ã®ä¾‹ï¼ˆ5ä»¶ï¼‰:\n",
      "   ç”»åƒID               æ­£è§£         Top1äºˆæ¸¬      Top2äºˆæ¸¬        Top3äºˆæ¸¬\n",
      "0     1       air hockey   cheerleading  air hockey  table tennis\n",
      "1     2       air hockey     volleyball  air hockey        hockey\n",
      "3     4       air hockey     pole vault       rings       archery\n",
      "5     6  ampute football   cheerleading         bmx    tug of war\n",
      "6     7  ampute football  horse jumping    football  field hockey\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# CSVèª­ã¿è¾¼ã¿\n",
    "df = pd.read_csv(os.path.join(test_path, \"prediction_results.csv\"))\n",
    "\n",
    "# Top1ãƒ»Top3 ç²¾åº¦ç®—å‡º\n",
    "top1_correct = df['æ­£è§£'] == df['Top1äºˆæ¸¬']\n",
    "top3_correct = df.apply(lambda row: row['æ­£è§£'] in [row['Top1äºˆæ¸¬'], row['Top2äºˆæ¸¬'], row['Top3äºˆæ¸¬']], axis=1)\n",
    "\n",
    "top1_accuracy = top1_correct.mean()\n",
    "top3_accuracy = top3_correct.mean()\n",
    "\n",
    "print(f\"ğŸ¯ Top1ç²¾åº¦: {top1_accuracy:.2%}\")\n",
    "print(f\"ğŸ¯ Top3ç²¾åº¦: {top3_accuracy:.2%}\")\n",
    "\n",
    "# ã‚¯ãƒ©ã‚¹åˆ¥ã®Top1æ­£è§£ç‡\n",
    "class_accuracy = df.groupby('æ­£è§£')['Top1äºˆæ¸¬'].apply(lambda x: (x == x.name).mean())\n",
    "print(\"\\nğŸ“ˆ ã‚¯ãƒ©ã‚¹åˆ¥ Top1ç²¾åº¦ï¼ˆä¸Šä½10ã‚¯ãƒ©ã‚¹ï¼‰:\")\n",
    "print(class_accuracy.sort_values(ascending=False).head(10))\n",
    "\n",
    "# Top1ã§é–“é•ãˆãŸå ´åˆã®ç›¸æ‰‹é›†è¨ˆ\n",
    "errors = df[~top1_correct]\n",
    "confusions = errors.groupby(['æ­£è§£', 'Top1äºˆæ¸¬']).size().reset_index(name='ä»¶æ•°')\n",
    "confusions = confusions.sort_values('ä»¶æ•°', ascending=False)\n",
    "print(\"\\nğŸŒ€ ã‚ˆãã‚ã‚‹æ··åŒä¾‹ï¼ˆTop10ï¼‰:\")\n",
    "print(confusions.head(10))\n",
    "\n",
    "# æ­£è§£ãƒ»Top1äºˆæ¸¬ãŒç•°ãªã‚‹ä¾‹ï¼ˆæŠœç²‹ï¼‰\n",
    "print(\"\\nğŸ” äºˆæ¸¬ãƒŸã‚¹ã®ä¾‹ï¼ˆ5ä»¶ï¼‰:\")\n",
    "print(errors[['ç”»åƒID', 'æ­£è§£', 'Top1äºˆæ¸¬', 'Top2äºˆæ¸¬', 'Top3äºˆæ¸¬']].head(5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
