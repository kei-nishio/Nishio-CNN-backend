{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0139e93",
   "metadata": {},
   "source": [
    "# 100 Sports Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec69d0c",
   "metadata": {},
   "source": [
    "## データのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f18044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初回のみ実行\n",
    "\n",
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"gpiosenka/sports-classification\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9b5278",
   "metadata": {},
   "source": [
    "## データの表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd812233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class id</th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "      <th>data set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>train/air hockey/001.jpg</td>\n",
       "      <td>air hockey</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>train/air hockey/002.jpg</td>\n",
       "      <td>air hockey</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>train/air hockey/003.jpg</td>\n",
       "      <td>air hockey</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>train/air hockey/004.jpg</td>\n",
       "      <td>air hockey</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>train/air hockey/005.jpg</td>\n",
       "      <td>air hockey</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class id                 filepaths      labels data set\n",
       "0         0  train/air hockey/001.jpg  air hockey    train\n",
       "1         0  train/air hockey/002.jpg  air hockey    train\n",
       "2         0  train/air hockey/003.jpg  air hockey    train\n",
       "3         0  train/air hockey/004.jpg  air hockey    train\n",
       "4         0  train/air hockey/005.jpg  air hockey    train"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = './kagglehub_cache/datasets/gpiosenka/sports-classification/versions/9/'\n",
    "csv_path = data_path + 'sports.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881ccc71",
   "metadata": {},
   "source": [
    "### カテゴリ列のユニーク値チェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ac917b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set 列のユニーク値 (3 個):\n",
      "  train: 13493 件\n",
      "  test: 500 件\n",
      "  valid: 500 件\n"
     ]
    }
   ],
   "source": [
    "# categorical_columns = [\"labels\",'data set']\n",
    "categorical_columns = ['data set']\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        unique_values = df[col].value_counts()\n",
    "        print(f\"{col} 列のユニーク値 ({len(unique_values)} 個):\")\n",
    "        for value, count in unique_values.items():\n",
    "            print(f\"  {value}: {count} 件\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a00fa6",
   "metadata": {},
   "source": [
    "## データの分離"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79bc47f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class id</th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "      <th>data set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>train/air hockey/001.jpg</td>\n",
       "      <td>air hockey</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>train/air hockey/002.jpg</td>\n",
       "      <td>air hockey</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>train/air hockey/003.jpg</td>\n",
       "      <td>air hockey</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>train/air hockey/004.jpg</td>\n",
       "      <td>air hockey</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>train/air hockey/005.jpg</td>\n",
       "      <td>air hockey</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class id                 filepaths      labels data set\n",
       "0         0  train/air hockey/001.jpg  air hockey    train\n",
       "1         0  train/air hockey/002.jpg  air hockey    train\n",
       "2         0  train/air hockey/003.jpg  air hockey    train\n",
       "3         0  train/air hockey/004.jpg  air hockey    train\n",
       "4         0  train/air hockey/005.jpg  air hockey    train"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = df[df['data set'] == 'train']\n",
    "df_test = df[df['data set'] == 'test']\n",
    "df_valid = df[df['data set'] == 'valid']\n",
    "\n",
    "display(df_train.head())\n",
    "# display(df_test.head())\n",
    "# display(df_valid.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e210fe4",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b90f06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 05:12:47.622134: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-25 05:12:47.623025: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-25 05:12:47.627141: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-25 05:12:47.637277: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753420367.654489   57006 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753420367.660310   57006 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753420367.675428   57006 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753420367.675457   57006 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753420367.675458   57006 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753420367.675459   57006 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-25 05:12:47.680374: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e5350b",
   "metadata": {},
   "source": [
    "### データの前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2d0734",
   "metadata": {},
   "source": [
    "#### 訓練用データセットの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed51942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13492 images belonging to 100 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "train_set = train_datagen.flow_from_directory(data_path + 'train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "# 2分類の場合は class_mode = 'binary' を指定\n",
    "# 多分類の場合は class_mode = 'categorical' を指定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05694ef3",
   "metadata": {},
   "source": [
    "#### 検証用データセットの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7c9901a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 100 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "valid_set = valid_datagen.flow_from_directory(data_path + 'valid',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9c9cde",
   "metadata": {},
   "source": [
    "#### テストデータセットの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e2ff1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 100 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "test_set = test_datagen.flow_from_directory(data_path + 'test',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9734aaff",
   "metadata": {},
   "source": [
    "### CNNの構築"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9f9298",
   "metadata": {},
   "source": [
    "#### イニシャライズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10c4731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbd8dda",
   "metadata": {},
   "source": [
    "#### 畳み込みandプーリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c76a065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-07-25 05:12:51.676358: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# 一層目\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "# 二層目\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fd9705",
   "metadata": {},
   "source": [
    "#### Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b16fa657",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4489176",
   "metadata": {},
   "source": [
    "#### 出力層の追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9eb5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=100, activation='softmax'))\n",
    "# 2分類の場合は units=1, activation='sigmoid' を指定\n",
    "# 多分類の場合は units=[number], activation='softmax' を指定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30987574",
   "metadata": {},
   "source": [
    "### モデル学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392e8ce8",
   "metadata": {},
   "source": [
    "#### モデルのコンパイルと訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5f801ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "# 2分類の場合は loss = 'binary_crossentropy' を指定\n",
    "# 多分類の場合は loss = 'categorical_crossentropy' を指定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a663a184",
   "metadata": {},
   "source": [
    "#### モデルの訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db6d691c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - accuracy: 0.0407 - loss: 4.3837"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 348ms/step - accuracy: 0.0408 - loss: 4.3830 - val_accuracy: 0.1980 - val_loss: 3.4623\n",
      "Epoch 2/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 246ms/step - accuracy: 0.1960 - loss: 3.3200 - val_accuracy: 0.2860 - val_loss: 2.8612\n",
      "Epoch 3/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 273ms/step - accuracy: 0.2976 - loss: 2.7924 - val_accuracy: 0.3280 - val_loss: 2.6469\n",
      "Epoch 4/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 270ms/step - accuracy: 0.3646 - loss: 2.5026 - val_accuracy: 0.3520 - val_loss: 2.4917\n",
      "Epoch 5/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 279ms/step - accuracy: 0.4068 - loss: 2.3014 - val_accuracy: 0.3980 - val_loss: 2.3533\n",
      "Epoch 6/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 300ms/step - accuracy: 0.4526 - loss: 2.1288 - val_accuracy: 0.4280 - val_loss: 2.2840\n",
      "Epoch 7/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 267ms/step - accuracy: 0.4657 - loss: 2.0185 - val_accuracy: 0.4380 - val_loss: 2.2212\n",
      "Epoch 8/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 414ms/step - accuracy: 0.5185 - loss: 1.8364 - val_accuracy: 0.4280 - val_loss: 2.2069\n",
      "Epoch 9/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 372ms/step - accuracy: 0.5248 - loss: 1.8035 - val_accuracy: 0.4320 - val_loss: 2.0903\n",
      "Epoch 10/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 279ms/step - accuracy: 0.5499 - loss: 1.6899 - val_accuracy: 0.4360 - val_loss: 2.1719\n",
      "Epoch 11/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 312ms/step - accuracy: 0.5640 - loss: 1.6269 - val_accuracy: 0.4140 - val_loss: 2.2984\n",
      "Epoch 12/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 292ms/step - accuracy: 0.5785 - loss: 1.5397 - val_accuracy: 0.4740 - val_loss: 2.2161\n",
      "Epoch 13/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 320ms/step - accuracy: 0.5987 - loss: 1.4365 - val_accuracy: 0.4420 - val_loss: 2.2021\n",
      "Epoch 14/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 289ms/step - accuracy: 0.6232 - loss: 1.3733 - val_accuracy: 0.4600 - val_loss: 2.2991\n",
      "Epoch 15/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 309ms/step - accuracy: 0.6356 - loss: 1.3020 - val_accuracy: 0.4360 - val_loss: 2.2643\n",
      "Epoch 16/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 305ms/step - accuracy: 0.6479 - loss: 1.2723 - val_accuracy: 0.4240 - val_loss: 2.3486\n",
      "Epoch 17/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 311ms/step - accuracy: 0.6531 - loss: 1.2277 - val_accuracy: 0.4380 - val_loss: 2.4277\n",
      "Epoch 18/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 312ms/step - accuracy: 0.6730 - loss: 1.1529 - val_accuracy: 0.4500 - val_loss: 2.3255\n",
      "Epoch 19/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 313ms/step - accuracy: 0.6759 - loss: 1.1286 - val_accuracy: 0.4400 - val_loss: 2.3761\n",
      "Epoch 20/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 320ms/step - accuracy: 0.6790 - loss: 1.1174 - val_accuracy: 0.4380 - val_loss: 2.4326\n",
      "Epoch 21/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 297ms/step - accuracy: 0.6927 - loss: 1.0752 - val_accuracy: 0.4540 - val_loss: 2.4411\n",
      "Epoch 22/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 327ms/step - accuracy: 0.7177 - loss: 1.0019 - val_accuracy: 0.4500 - val_loss: 2.5345\n",
      "Epoch 23/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 279ms/step - accuracy: 0.7164 - loss: 0.9948 - val_accuracy: 0.4620 - val_loss: 2.4771\n",
      "Epoch 24/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 276ms/step - accuracy: 0.7292 - loss: 0.9430 - val_accuracy: 0.4540 - val_loss: 2.5824\n",
      "Epoch 25/25\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 253ms/step - accuracy: 0.7318 - loss: 0.9602 - val_accuracy: 0.4480 - val_loss: 2.5887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f54502f72f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = train_set, validation_data = valid_set, epochs = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ada2762",
   "metadata": {},
   "source": [
    "## 結果の出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5e4bee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "クラスインデックス（class_indices）を JSON 出力しました。\n",
      "モデルを保存しました。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# クラス名のマッピング（index → label）\n",
    "class_indices = train_set.class_indices\n",
    "\n",
    "# 保存用ディレクトリ\n",
    "model_path = './backend/ml'\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "# class_indices を JSON に保存（例: { 'air hockey': 0, 'archery': 1, ... }）\n",
    "with open(os.path.join(model_path, \"class_indices.json\"), \"w\") as f:\n",
    "    json.dump(class_indices, f, indent=2, ensure_ascii=False)\n",
    "print(\"クラスインデックス（class_indices）を JSON 出力しました。\")\n",
    "\n",
    "# モデル保存\n",
    "cnn.save(os.path.join(model_path, 'sports_classification_model.h5'))\n",
    "print(\"モデルを保存しました。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
